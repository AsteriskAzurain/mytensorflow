一般的神经网络，
输入Beijing会得到相同的输出，
是不足以用于识别语义的，
识别语义需要记住上下文。<br>
---
<h3>RNN</h3>
<h4>是一种对序列型数据进行建模的深度模型</h4>
初始状态h0<br>
+网络输入值x1<br>
=结果h1  --> **网络输出**<br>
+网络输入值x2<br>
=结果h2  --> **网络输出**<br>
+输入...<br>
<h4><font color='red'>每层有两个输入：上一时刻的状态和此时刻的输入<br>——网络具有记忆功能</font></h4>
<h4>RNN特别适合于处理有时间序列的数据</h4>
---
每个时刻的网络结构和权值是一样的
每个时刻循环<br>
但每次的隐层不一样 每次的隐层都为上一时刻的隐层输出<br>
也就是说 是隐层具有记忆功能<br>
h1 包含 h0<br>
h2 包含 h1 即同时包含了h0<br>
以此类推 最后时刻包含了全部的时刻信息<br>
<h4>模型希望能包含尽量多的时刻信息 以更好地判断语义</h4>
---
原始的RNN结构输入x于输出y的序列必须是等长的<br>
x1 → y1<br>
......<br>
xn → yn<br>
两边的n必须相等<br>
但与x y的维数无关
---
改善模型的方式：
（也是）更新模型的权值和阈值<br>
权值：
1. v 输出层神经元对隐层的权值
1. u 隐层对输入层的权值
1. w 当前时刻神经元对上一时刻隐层的权值
<h4>BPTT随时间反向传播方法</h4>
---
<h3>RNN的用途<h3>
1. n vs 1
    - 文本的分类
    - 句子情感倾向
    - 视频类别

1. 1 vs n
    - 图像生成文字(图片内容的关键词)
    - 从类别生成音乐或语音
    
1. m vs n
---
